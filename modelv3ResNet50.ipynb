{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 15:17:03.788426: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-01 15:17:03.799389: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-01 15:17:03.815290: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-01 15:17:03.815314: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-01 15:17:03.825334: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-01 15:17:04.446925: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-07-01 15:17:05.258088: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The name \"conv1_pad\" is used 3 times in the model. All operation names should be unique.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 92\u001b[0m\n\u001b[1;32m     89\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Build ResNet50 model\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m resnet50_model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_resnet50_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m resnet50_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Define early stopping and model checkpoint callbacks\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 84\u001b[0m, in \u001b[0;36mbuild_resnet50_model\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m     81\u001b[0m x \u001b[38;5;241m=\u001b[39m Dropout(\u001b[38;5;241m0.5\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout_128\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[1;32m     82\u001b[0m outputs \u001b[38;5;241m=\u001b[39m Dense(num_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[0;32m---> 84\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43minputs_rp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_gaf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_mtf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/utils/tracking.py:26\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m DotNotTrackScope():\n\u001b[0;32m---> 26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/models/functional.py:135\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(is_input_keras_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m flat_inputs):\n\u001b[1;32m    133\u001b[0m     inputs, outputs \u001b[38;5;241m=\u001b[39m clone_graph_nodes(inputs, outputs)\n\u001b[0;32m--> 135\u001b[0m \u001b[43mFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m trainable\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/ops/function.py:77\u001b[0m, in \u001b[0;36mFunction.__init__\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m _self_setattr_tracking\n\u001b[0;32m---> 77\u001b[0m (nodes, nodes_by_depth, operations, operations_by_depth) \u001b[38;5;241m=\u001b[39m \u001b[43mmap_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_outputs\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes \u001b[38;5;241m=\u001b[39m nodes\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes_by_depth \u001b[38;5;241m=\u001b[39m nodes_by_depth\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/ops/function.py:331\u001b[0m, in \u001b[0;36mmap_graph\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m all_names:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m all_names\u001b[38;5;241m.\u001b[39mcount(name) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    332\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe name \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is used \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mall_names\u001b[38;5;241m.\u001b[39mcount(name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    333\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimes in the model. All operation names should be unique.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m         )\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m network_nodes, nodes_by_depth, operations, operations_by_depth\n",
      "\u001b[0;31mValueError\u001b[0m: The name \"conv1_pad\" is used 3 times in the model. All operation names should be unique."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Concatenate, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Define a custom callback to print messages and store history\n",
    "class PrintLogger(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"\\nEpoch {epoch + 1} started.\")\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"\\nEpoch {epoch + 1} ended.\")\n",
    "        print(f\"Accuracy: {logs['accuracy']:.4f} - Loss: {logs['loss']:.4f} - Val Accuracy: {logs['val_accuracy']:.4f} - Val Loss: {logs['val_loss']:.4f}\")\n",
    "\n",
    "# Define directories\n",
    "save_dir = './split_datav3'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Load the split data\n",
    "X_rp_train = np.load(os.path.join(save_dir, 'X_rp_train.npy'))\n",
    "X_gaf_train = np.load(os.path.join(save_dir, 'X_gaf_train.npy'))\n",
    "X_mtf_train = np.load(os.path.join(save_dir, 'X_mtf_train.npy'))\n",
    "y_train = np.load(os.path.join(save_dir, 'y_train.npy'))\n",
    "\n",
    "X_rp_val = np.load(os.path.join(save_dir, 'X_rp_val.npy'))\n",
    "X_gaf_val = np.load(os.path.join(save_dir, 'X_gaf_val.npy'))\n",
    "X_mtf_val = np.load(os.path.join(save_dir, 'X_mtf_val.npy'))\n",
    "y_val = np.load(os.path.join(save_dir, 'y_val.npy'))\n",
    "\n",
    "X_rp_test = np.load(os.path.join(save_dir, 'X_rp_test.npy'))\n",
    "X_gaf_test = np.load(os.path.join(save_dir, 'X_gaf_test.npy'))\n",
    "X_mtf_test = np.load(os.path.join(save_dir, 'X_mtf_test.npy'))\n",
    "y_test = np.load(os.path.join(save_dir, 'y_test.npy'))\n",
    "\n",
    "# Resize images to (224, 224, 3) and keep only RGB channels\n",
    "def resize_images(images):\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        img = tf.image.resize(img, [224, 224])\n",
    "        img = img[:, :, :3]  # Keep only RGB channels\n",
    "        resized_images.append(img)\n",
    "    return np.array(resized_images)\n",
    "\n",
    "X_rp_train = resize_images(X_rp_train)\n",
    "X_gaf_train = resize_images(X_gaf_train)\n",
    "X_mtf_train = resize_images(X_mtf_train)\n",
    "X_rp_val = resize_images(X_rp_val)\n",
    "X_gaf_val = resize_images(X_gaf_val)\n",
    "X_mtf_val = resize_images(X_mtf_val)\n",
    "X_rp_test = resize_images(X_rp_test)\n",
    "X_gaf_test = resize_images(X_gaf_test)\n",
    "X_mtf_test = resize_images(X_mtf_test)\n",
    "\n",
    "# Define a function to build the ResNet50 model\n",
    "def build_resnet50_model(input_shape, num_classes):\n",
    "    inputs_rp = Input(shape=input_shape, name='input_rp')\n",
    "    inputs_gaf = Input(shape=input_shape, name='input_gaf')\n",
    "    inputs_mtf = Input(shape=input_shape, name='input_mtf')\n",
    "\n",
    "    base_rp = ResNet50(include_top=False, input_tensor=inputs_rp, weights='imagenet', pooling='avg')\n",
    "    base_gaf = ResNet50(include_top=False, input_tensor=inputs_gaf, weights='imagenet', pooling='avg')\n",
    "    base_mtf = ResNet50(include_top=False, input_tensor=inputs_mtf, weights='imagenet', pooling='avg')\n",
    "\n",
    "    x_rp = base_rp.output\n",
    "    x_gaf = base_gaf.output\n",
    "    x_mtf = base_mtf.output\n",
    "\n",
    "    merged = Concatenate(name='concat')([x_rp, x_gaf, x_mtf])\n",
    "\n",
    "    x = Dense(512, activation='relu', name='dense_512')(merged)\n",
    "    x = Dropout(0.5, name='dropout_512')(x)\n",
    "    x = Dense(128, activation='relu', name='dense_128')(x)\n",
    "    x = Dropout(0.5, name='dropout_128')(x)\n",
    "    outputs = Dense(num_classes, activation='softmax', name='output')(x)\n",
    "\n",
    "    model = Model(inputs=[inputs_rp, inputs_gaf, inputs_mtf], outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = 5\n",
    "\n",
    "# Build ResNet50 model\n",
    "resnet50_model = build_resnet50_model(input_shape, num_classes)\n",
    "resnet50_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping and model checkpoint callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "resnet50_checkpoint = ModelCheckpoint(filepath=os.path.join(save_dir, 'resnet50_best_model.h5'), monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Train ResNet50 model\n",
    "resnet50_history = resnet50_model.fit(\n",
    "    [X_rp_train, X_gaf_train, X_mtf_train], y_train,\n",
    "    epochs=10, batch_size=32, validation_data=([X_rp_val, X_gaf_val, X_mtf_val], y_val),\n",
    "    callbacks=[early_stopping, resnet50_checkpoint, PrintLogger()],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate ResNet50 model on the test set\n",
    "resnet50_model.load_weights(os.path.join(save_dir, 'resnet50_best_model.h5'))\n",
    "resnet50_test_loss, resnet50_test_accuracy = resnet50_model.evaluate([X_rp_test, X_gaf_test, X_mtf_test], y_test)\n",
    "print(f'ResNet50 Test loss: {resnet50_test_loss:.4f}')\n",
    "print(f'ResNet50 Test accuracy: {resnet50_test_accuracy:.4f}')\n",
    "\n",
    "# Function to plot learning curves\n",
    "def plot_learning_curve(history, model_name):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(f'Model accuracy - {model_name}')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'Model loss - {model_name}')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot learning curve for ResNet50\n",
    "plot_learning_curve(resnet50_history, 'ResNet50')\n",
    "\n",
    "# Save the final ResNet50 model\n",
    "resnet50_model.save(os.path.join(save_dir, 'resnet50_model.h5'))\n",
    "\n",
    "# Save the training history\n",
    "with open(os.path.join(save_dir, 'resnet50_history.json'), 'w') as f:\n",
    "    json.dump(resnet50_history.history, f)\n",
    "\n",
    "print(f\"ResNet50 model and history saved in directory: {save_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The name \"resnet50\" is used 3 times in the model. All operation names should be unique.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 99\u001b[0m\n\u001b[1;32m     96\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Build ResNet50 model\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m resnet50_model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_resnet50_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m resnet50_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Define early stopping and model checkpoint callbacks\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 91\u001b[0m, in \u001b[0;36mbuild_resnet50_model\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m     88\u001b[0m x \u001b[38;5;241m=\u001b[39m Dropout(\u001b[38;5;241m0.5\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout_128\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[1;32m     89\u001b[0m outputs \u001b[38;5;241m=\u001b[39m Dense(num_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[0;32m---> 91\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43minputs_rp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_gaf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_mtf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/utils/tracking.py:26\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m DotNotTrackScope():\n\u001b[0;32m---> 26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/models/functional.py:135\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(is_input_keras_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m flat_inputs):\n\u001b[1;32m    133\u001b[0m     inputs, outputs \u001b[38;5;241m=\u001b[39m clone_graph_nodes(inputs, outputs)\n\u001b[0;32m--> 135\u001b[0m \u001b[43mFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m trainable\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/ops/function.py:77\u001b[0m, in \u001b[0;36mFunction.__init__\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m _self_setattr_tracking\n\u001b[0;32m---> 77\u001b[0m (nodes, nodes_by_depth, operations, operations_by_depth) \u001b[38;5;241m=\u001b[39m \u001b[43mmap_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_outputs\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes \u001b[38;5;241m=\u001b[39m nodes\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes_by_depth \u001b[38;5;241m=\u001b[39m nodes_by_depth\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/ops/function.py:331\u001b[0m, in \u001b[0;36mmap_graph\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m all_names:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m all_names\u001b[38;5;241m.\u001b[39mcount(name) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    332\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe name \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is used \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mall_names\u001b[38;5;241m.\u001b[39mcount(name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    333\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimes in the model. All operation names should be unique.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m         )\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m network_nodes, nodes_by_depth, operations, operations_by_depth\n",
      "\u001b[0;31mValueError\u001b[0m: The name \"resnet50\" is used 3 times in the model. All operation names should be unique."
     ]
    }
   ],
   "source": [
    "#Debugging\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model, clone_model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Concatenate, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Define a custom callback to print messages and store history\n",
    "class PrintLogger(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"\\nEpoch {epoch + 1} started.\")\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"\\nEpoch {epoch + 1} ended.\")\n",
    "        print(f\"Accuracy: {logs['accuracy']:.4f} - Loss: {logs['loss']:.4f} - Val Accuracy: {logs['val_accuracy']:.4f} - Val Loss: {logs['val_loss']:.4f}\")\n",
    "\n",
    "# Define directories\n",
    "save_dir = './split_datav3'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Load the split data\n",
    "X_rp_train = np.load(os.path.join(save_dir, 'X_rp_train.npy'))\n",
    "X_gaf_train = np.load(os.path.join(save_dir, 'X_gaf_train.npy'))\n",
    "X_mtf_train = np.load(os.path.join(save_dir, 'X_mtf_train.npy'))\n",
    "y_train = np.load(os.path.join(save_dir, 'y_train.npy'))\n",
    "\n",
    "X_rp_val = np.load(os.path.join(save_dir, 'X_rp_val.npy'))\n",
    "X_gaf_val = np.load(os.path.join(save_dir, 'X_gaf_val.npy'))\n",
    "X_mtf_val = np.load(os.path.join(save_dir, 'X_mtf_val.npy'))\n",
    "y_val = np.load(os.path.join(save_dir, 'y_val.npy'))\n",
    "\n",
    "X_rp_test = np.load(os.path.join(save_dir, 'X_rp_test.npy'))\n",
    "X_gaf_test = np.load(os.path.join(save_dir, 'X_gaf_test.npy'))\n",
    "X_mtf_test = np.load(os.path.join(save_dir, 'X_mtf_test.npy'))\n",
    "y_test = np.load(os.path.join(save_dir, 'y_test.npy'))\n",
    "\n",
    "# Resize images to (224, 224, 3) and keep only RGB channels\n",
    "def resize_images(images):\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        img = tf.image.resize(img, [224, 224])\n",
    "        img = img[:, :, :3]  # Keep only RGB channels\n",
    "        resized_images.append(img)\n",
    "    return np.array(resized_images)\n",
    "\n",
    "X_rp_train = resize_images(X_rp_train)\n",
    "X_gaf_train = resize_images(X_gaf_train)\n",
    "X_mtf_train = resize_images(X_mtf_train)\n",
    "X_rp_val = resize_images(X_rp_val)\n",
    "X_gaf_val = resize_images(X_gaf_val)\n",
    "X_mtf_val = resize_images(X_mtf_val)\n",
    "X_rp_test = resize_images(X_rp_test)\n",
    "X_gaf_test = resize_images(X_gaf_test)\n",
    "X_mtf_test = resize_images(X_mtf_test)\n",
    "\n",
    "# Define a function to build the ResNet50 model using clone_model\n",
    "def build_resnet50_model(input_shape, num_classes):\n",
    "    inputs_rp = Input(shape=input_shape, name='input_rp')\n",
    "    inputs_gaf = Input(shape=input_shape, name='input_gaf')\n",
    "    inputs_mtf = Input(shape=input_shape, name='input_mtf')\n",
    "\n",
    "    base_model = ResNet50(include_top=False, weights='imagenet', pooling='avg')\n",
    "\n",
    "    base_rp = clone_model(base_model)\n",
    "    base_rp.set_weights(base_model.get_weights())\n",
    "    x_rp = base_rp(inputs_rp)\n",
    "\n",
    "    base_gaf = clone_model(base_model)\n",
    "    base_gaf.set_weights(base_model.get_weights())\n",
    "    x_gaf = base_gaf(inputs_gaf)\n",
    "\n",
    "    base_mtf = clone_model(base_model)\n",
    "    base_mtf.set_weights(base_model.get_weights())\n",
    "    x_mtf = base_mtf(inputs_mtf)\n",
    "\n",
    "    merged = Concatenate(name='concat')([x_rp, x_gaf, x_mtf])\n",
    "\n",
    "    x = Dense(512, activation='relu', name='dense_512')(merged)\n",
    "    x = Dropout(0.5, name='dropout_512')(x)\n",
    "    x = Dense(128, activation='relu', name='dense_128')(x)\n",
    "    x = Dropout(0.5, name='dropout_128')(x)\n",
    "    outputs = Dense(num_classes, activation='softmax', name='output')(x)\n",
    "\n",
    "    model = Model(inputs=[inputs_rp, inputs_gaf, inputs_mtf], outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = 5\n",
    "\n",
    "# Build ResNet50 model\n",
    "resnet50_model = build_resnet50_model(input_shape, num_classes)\n",
    "resnet50_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping and model checkpoint callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "resnet50_checkpoint = ModelCheckpoint(filepath=os.path.join(save_dir, 'resnet50_best_model.h5'), monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Train ResNet50 model\n",
    "resnet50_history = resnet50_model.fit(\n",
    "    [X_rp_train, X_gaf_train, X_mtf_train], y_train,\n",
    "    epochs=10, batch_size=32, validation_data=([X_rp_val, X_gaf_val, X_mtf_val], y_val),\n",
    "    callbacks=[early_stopping, resnet50_checkpoint, PrintLogger()],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate ResNet50 model on the test set\n",
    "resnet50_model.load_weights(os.path.join(save_dir, 'resnet50_best_model.h5'))\n",
    "resnet50_test_loss, resnet50_test_accuracy = resnet50_model.evaluate([X_rp_test, X_gaf_test, X_mtf_test], y_test)\n",
    "print(f'ResNet50 Test loss: {resnet50_test_loss:.4f}')\n",
    "print(f'ResNet50 Test accuracy: {resnet50_test_accuracy:.4f}')\n",
    "\n",
    "# Function to plot learning curves\n",
    "def plot_learning_curve(history, model_name):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(f'Model accuracy - {model_name}')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'Model loss - {model_name}')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot learning curve for ResNet50\n",
    "plot_learning_curve(resnet50_history, 'ResNet50')\n",
    "\n",
    "# Save the final ResNet50 model\n",
    "resnet50_model.save(os.path.join(save_dir, 'resnet50_model.h5'))\n",
    "\n",
    "# Save the training history\n",
    "with open(os.path.join(save_dir, 'resnet50_history.json'), 'w') as f:\n",
    "    json.dump(resnet50_history.history, f)\n",
    "\n",
    "print(f\"ResNet50 model and history saved in directory: {save_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The name \"resnet50\" is used 3 times in the model. All operation names should be unique.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 103\u001b[0m\n\u001b[1;32m    100\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Build ResNet50 model\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m resnet50_model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_resnet50_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m resnet50_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Define early stopping and model checkpoint callbacks\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 95\u001b[0m, in \u001b[0;36mbuild_resnet50_model\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m     92\u001b[0m x \u001b[38;5;241m=\u001b[39m Dropout(\u001b[38;5;241m0.5\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout_128\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[1;32m     93\u001b[0m outputs \u001b[38;5;241m=\u001b[39m Dense(num_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[0;32m---> 95\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43minputs_rp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_gaf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_mtf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/utils/tracking.py:26\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m DotNotTrackScope():\n\u001b[0;32m---> 26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/models/functional.py:135\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(is_input_keras_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m flat_inputs):\n\u001b[1;32m    133\u001b[0m     inputs, outputs \u001b[38;5;241m=\u001b[39m clone_graph_nodes(inputs, outputs)\n\u001b[0;32m--> 135\u001b[0m \u001b[43mFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m trainable\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/ops/function.py:77\u001b[0m, in \u001b[0;36mFunction.__init__\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m _self_setattr_tracking\n\u001b[0;32m---> 77\u001b[0m (nodes, nodes_by_depth, operations, operations_by_depth) \u001b[38;5;241m=\u001b[39m \u001b[43mmap_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_outputs\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes \u001b[38;5;241m=\u001b[39m nodes\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes_by_depth \u001b[38;5;241m=\u001b[39m nodes_by_depth\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/ops/function.py:331\u001b[0m, in \u001b[0;36mmap_graph\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m all_names:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m all_names\u001b[38;5;241m.\u001b[39mcount(name) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    332\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe name \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is used \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mall_names\u001b[38;5;241m.\u001b[39mcount(name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    333\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimes in the model. All operation names should be unique.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m         )\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m network_nodes, nodes_by_depth, operations, operations_by_depth\n",
      "\u001b[0;31mValueError\u001b[0m: The name \"resnet50\" is used 3 times in the model. All operation names should be unique."
     ]
    }
   ],
   "source": [
    "#debug\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model, clone_model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Concatenate, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Define a custom callback to print messages and store history\n",
    "class PrintLogger(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"\\nEpoch {epoch + 1} started.\")\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"\\nEpoch {epoch + 1} ended.\")\n",
    "        print(f\"Accuracy: {logs['accuracy']:.4f} - Loss: {logs['loss']:.4f} - Val Accuracy: {logs['val_accuracy']:.4f} - Val Loss: {logs['val_loss']:.4f}\")\n",
    "\n",
    "# Define directories\n",
    "save_dir = './split_datav3'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Load the split data\n",
    "X_rp_train = np.load(os.path.join(save_dir, 'X_rp_train.npy'))\n",
    "X_gaf_train = np.load(os.path.join(save_dir, 'X_gaf_train.npy'))\n",
    "X_mtf_train = np.load(os.path.join(save_dir, 'X_mtf_train.npy'))\n",
    "y_train = np.load(os.path.join(save_dir, 'y_train.npy'))\n",
    "\n",
    "X_rp_val = np.load(os.path.join(save_dir, 'X_rp_val.npy'))\n",
    "X_gaf_val = np.load(os.path.join(save_dir, 'X_gaf_val.npy'))\n",
    "X_mtf_val = np.load(os.path.join(save_dir, 'X_mtf_val.npy'))\n",
    "y_val = np.load(os.path.join(save_dir, 'y_val.npy'))\n",
    "\n",
    "X_rp_test = np.load(os.path.join(save_dir, 'X_rp_test.npy'))\n",
    "X_gaf_test = np.load(os.path.join(save_dir, 'X_gaf_test.npy'))\n",
    "X_mtf_test = np.load(os.path.join(save_dir, 'X_mtf_test.npy'))\n",
    "y_test = np.load(os.path.join(save_dir, 'y_test.npy'))\n",
    "\n",
    "# Resize images to (224, 224, 3) and keep only RGB channels\n",
    "def resize_images(images):\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        img = tf.image.resize(img, [224, 224])\n",
    "        img = img[:, :, :3]  # Keep only RGB channels\n",
    "        resized_images.append(img)\n",
    "    return np.array(resized_images)\n",
    "\n",
    "X_rp_train = resize_images(X_rp_train)\n",
    "X_gaf_train = resize_images(X_gaf_train)\n",
    "X_mtf_train = resize_images(X_mtf_train)\n",
    "X_rp_val = resize_images(X_rp_val)\n",
    "X_gaf_val = resize_images(X_gaf_val)\n",
    "X_mtf_val = resize_images(X_mtf_val)\n",
    "X_rp_test = resize_images(X_rp_test)\n",
    "X_gaf_test = resize_images(X_gaf_test)\n",
    "X_mtf_test = resize_images(X_mtf_test)\n",
    "\n",
    "# Define a function to build the ResNet50 model using clone_model\n",
    "def build_resnet50_model(input_shape, num_classes):\n",
    "    inputs_rp = Input(shape=input_shape, name='input_rp')\n",
    "    inputs_gaf = Input(shape=input_shape, name='input_gaf')\n",
    "    inputs_mtf = Input(shape=input_shape, name='input_mtf')\n",
    "\n",
    "    base_model = ResNet50(include_top=False, weights='imagenet', pooling='avg')\n",
    "\n",
    "    # Clone the base model for each input with unique names\n",
    "    base_rp = clone_model(base_model)\n",
    "    base_rp._name = 'base_rp'\n",
    "    base_rp.set_weights(base_model.get_weights())\n",
    "    x_rp = base_rp(inputs_rp)\n",
    "\n",
    "    base_gaf = clone_model(base_model)\n",
    "    base_gaf._name = 'base_gaf'\n",
    "    base_gaf.set_weights(base_model.get_weights())\n",
    "    x_gaf = base_gaf(inputs_gaf)\n",
    "\n",
    "    base_mtf = clone_model(base_model)\n",
    "    base_mtf._name = 'base_mtf'\n",
    "    base_mtf.set_weights(base_model.get_weights())\n",
    "    x_mtf = base_mtf(inputs_mtf)\n",
    "\n",
    "    merged = Concatenate(name='concat')([x_rp, x_gaf, x_mtf])\n",
    "\n",
    "    x = Dense(512, activation='relu', name='dense_512')(merged)\n",
    "    x = Dropout(0.5, name='dropout_512')(x)\n",
    "    x = Dense(128, activation='relu', name='dense_128')(x)\n",
    "    x = Dropout(0.5, name='dropout_128')(x)\n",
    "    outputs = Dense(num_classes, activation='softmax', name='output')(x)\n",
    "\n",
    "    model = Model(inputs=[inputs_rp, inputs_gaf, inputs_mtf], outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = 5\n",
    "\n",
    "# Build ResNet50 model\n",
    "resnet50_model = build_resnet50_model(input_shape, num_classes)\n",
    "resnet50_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping and model checkpoint callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "resnet50_checkpoint = ModelCheckpoint(filepath=os.path.join(save_dir, 'resnet50_best_model.h5'), monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Train ResNet50 model\n",
    "resnet50_history = resnet50_model.fit(\n",
    "    [X_rp_train, X_gaf_train, X_mtf_train], y_train,\n",
    "    epochs=10, batch_size=32, validation_data=([X_rp_val, X_gaf_val, X_mtf_val], y_val),\n",
    "    callbacks=[early_stopping, resnet50_checkpoint, PrintLogger()],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate ResNet50 model on the test set\n",
    "resnet50_model.load_weights(os.path.join(save_dir, 'resnet50_best_model.h5'))\n",
    "resnet50_test_loss, resnet50_test_accuracy = resnet50_model.evaluate([X_rp_test, X_gaf_test, X_mtf_test], y_test)\n",
    "print(f'ResNet50 Test loss: {resnet50_test_loss:.4f}')\n",
    "print(f'ResNet50 Test accuracy: {resnet50_test_accuracy:.4f}')\n",
    "\n",
    "# Function to plot learning curves\n",
    "def plot_learning_curve(history, model_name):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(f'Model accuracy - {model_name}')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'Model loss - {model_name}')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot learning curve for ResNet50\n",
    "plot_learning_curve(resnet50_history, 'ResNet50')\n",
    "\n",
    "# Save the final ResNet50 model\n",
    "resnet50_model.save(os.path.join(save_dir, 'resnet50_model.h5'))\n",
    "\n",
    "# Save the training history\n",
    "with open(os.path.join(save_dir, 'resnet50_history.json'), 'w') as f:\n",
    "    json.dump(resnet50_history.history, f)\n",
    "\n",
    "print(f\"ResNet50 model and history saved in directory: {save_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newtestv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
