{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 15:59:10.703357: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-01 15:59:10.714615: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-01 15:59:10.730636: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-01 15:59:10.730658: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-01 15:59:10.740830: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-01 15:59:11.368678: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-07-01 15:59:12.169207: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The shape of the target variable and the shape of the target value in `variable.assign(value)` must match. variable.shape=(3, 3, 4, 64), Received: value.shape=(3, 3, 3, 64). Target variable: <KerasVariable shape=(3, 3, 4, 64), dtype=float32, path=block1_conv1/kernel>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Build VGG16 model\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m vgg16_model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_vgg16_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m vgg16_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Define early stopping and model checkpoint callbacks\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 50\u001b[0m, in \u001b[0;36mbuild_vgg16_model\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m     47\u001b[0m inputs_gaf \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39minput_shape)\n\u001b[1;32m     48\u001b[0m inputs_mtf \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39minput_shape)\n\u001b[0;32m---> 50\u001b[0m base_rp \u001b[38;5;241m=\u001b[39m \u001b[43mVGG16\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_rp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m base_gaf \u001b[38;5;241m=\u001b[39m VGG16(include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, input_tensor\u001b[38;5;241m=\u001b[39minputs_gaf)\n\u001b[1;32m     52\u001b[0m base_mtf \u001b[38;5;241m=\u001b[39m VGG16(include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, input_tensor\u001b[38;5;241m=\u001b[39minputs_mtf)\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/applications/vgg16.py:224\u001b[0m, in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m         weights_path \u001b[38;5;241m=\u001b[39m file_utils\u001b[38;5;241m.\u001b[39mget_file(\n\u001b[1;32m    219\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m             WEIGHTS_PATH_NO_TOP,\n\u001b[1;32m    221\u001b[0m             cache_subdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m             file_hash\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m6d6bbae143d832006294945121d1f1fc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         )\n\u001b[0;32m--> 224\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_weights(weights)\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/backend/common/variables.py:226\u001b[0m, in \u001b[0;36mKerasVariable.assign\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    224\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_to_tensor(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m shape_equal(value\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m--> 226\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe shape of the target variable and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe shape of the target value in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`variable.assign(value)` must match. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariable.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: value.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget variable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m     )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m in_stateless_scope():\n\u001b[1;32m    235\u001b[0m     scope \u001b[38;5;241m=\u001b[39m get_stateless_scope()\n",
      "\u001b[0;31mValueError\u001b[0m: The shape of the target variable and the shape of the target value in `variable.assign(value)` must match. variable.shape=(3, 3, 4, 64), Received: value.shape=(3, 3, 3, 64). Target variable: <KerasVariable shape=(3, 3, 4, 64), dtype=float32, path=block1_conv1/kernel>"
     ]
    }
   ],
   "source": [
    "# VGG16\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Concatenate, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Define a custom callback to print messages and store history\n",
    "class PrintLogger(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"\\nEpoch {epoch + 1} started.\")\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"\\nEpoch {epoch + 1} ended.\")\n",
    "        print(f\"Accuracy: {logs['accuracy']:.4f} - Loss: {logs['loss']:.4f} - Val Accuracy: {logs['val_accuracy']:.4f} - Val Loss: {logs['val_loss']:.4f}\")\n",
    "\n",
    "# Define directories\n",
    "save_dir = './split_datav3'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Load the split data\n",
    "X_rp_train = np.load(os.path.join(save_dir, 'X_rp_train.npy'))\n",
    "X_gaf_train = np.load(os.path.join(save_dir, 'X_gaf_train.npy'))\n",
    "X_mtf_train = np.load(os.path.join(save_dir, 'X_mtf_train.npy'))\n",
    "y_train = np.load(os.path.join(save_dir, 'y_train.npy'))\n",
    "\n",
    "X_rp_val = np.load(os.path.join(save_dir, 'X_rp_val.npy'))\n",
    "X_gaf_val = np.load(os.path.join(save_dir, 'X_gaf_val.npy'))\n",
    "X_mtf_val = np.load(os.path.join(save_dir, 'X_mtf_val.npy'))\n",
    "y_val = np.load(os.path.join(save_dir, 'y_val.npy'))\n",
    "\n",
    "X_rp_test = np.load(os.path.join(save_dir, 'X_rp_test.npy'))\n",
    "X_gaf_test = np.load(os.path.join(save_dir, 'X_gaf_test.npy'))\n",
    "X_mtf_test = np.load(os.path.join(save_dir, 'X_mtf_test.npy'))\n",
    "y_test = np.load(os.path.join(save_dir, 'y_test.npy'))\n",
    "\n",
    "# Define a function to build the VGG16 model\n",
    "def build_vgg16_model(input_shape, num_classes):\n",
    "    inputs_rp = Input(shape=input_shape)\n",
    "    inputs_gaf = Input(shape=input_shape)\n",
    "    inputs_mtf = Input(shape=input_shape)\n",
    "    \n",
    "    base_rp = VGG16(include_top=False, input_tensor=inputs_rp)\n",
    "    base_gaf = VGG16(include_top=False, input_tensor=inputs_gaf)\n",
    "    base_mtf = VGG16(include_top=False, input_tensor=inputs_mtf)\n",
    "    \n",
    "    x_rp = Flatten()(base_rp.output)\n",
    "    x_gaf = Flatten()(base_gaf.output)\n",
    "    x_mtf = Flatten()(base_mtf.output)\n",
    "    \n",
    "    merged = Concatenate()([x_rp, x_gaf, x_mtf])\n",
    "    \n",
    "    x = Dense(512, activation='relu')(merged)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=[inputs_rp, inputs_gaf, inputs_mtf], outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (201, 201, 4)\n",
    "num_classes = 5\n",
    "\n",
    "# Build VGG16 model\n",
    "vgg16_model = build_vgg16_model(input_shape, num_classes)\n",
    "vgg16_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping and model checkpoint callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "vgg16_checkpoint = ModelCheckpoint(filepath=os.path.join(save_dir, 'vgg16_best_model.h5'), monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Train VGG16 model\n",
    "vgg16_history = vgg16_model.fit(\n",
    "    [X_rp_train, X_gaf_train, X_mtf_train], y_train,\n",
    "    epochs=10, batch_size=32, validation_data=([X_rp_val, X_gaf_val, X_mtf_val], y_val),\n",
    "    callbacks=[early_stopping, vgg16_checkpoint, PrintLogger()],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate VGG16 model on the test set\n",
    "vgg16_model.load_weights(os.path.join(save_dir, 'vgg16_best_model.h5'))\n",
    "vgg16_test_loss, vgg16_test_accuracy = vgg16_model.evaluate([X_rp_test, X_gaf_test, X_mtf_test], y_test)\n",
    "print(f'VGG16 Test loss: {vgg16_test_loss:.4f}')\n",
    "print(f'VGG16 Test accuracy: {vgg16_test_accuracy:.4f}')\n",
    "\n",
    "# Function to plot learning curves\n",
    "def plot_learning_curve(history, model_name):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot training & validation accuracy values\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(f'Model accuracy - {model_name}')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'Model loss - {model_name}')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot learning curve for VGG16\n",
    "plot_learning_curve(vgg16_history, 'VGG16')\n",
    "\n",
    "# Save the final VGG16 model\n",
    "vgg16_model.save(os.path.join(save_dir, 'vgg16_model.h5'))\n",
    "\n",
    "# Save the training history\n",
    "with open(os.path.join(save_dir, 'vgg16_history.json'), 'w') as f:\n",
    "    json.dump(vgg16_history.history, f)\n",
    "\n",
    "print(f\"VGG16 model and history saved in directory: {save_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The name \"block1_conv1\" is used 3 times in the model. All operation names should be unique.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 96\u001b[0m\n\u001b[1;32m     93\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Build VGG16 model\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m vgg16_model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_vgg16_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m vgg16_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Define early stopping and model checkpoint callbacks\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 88\u001b[0m, in \u001b[0;36mbuild_vgg16_model\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m     85\u001b[0m x \u001b[38;5;241m=\u001b[39m Dropout(\u001b[38;5;241m0.5\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout_128\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[1;32m     86\u001b[0m outputs \u001b[38;5;241m=\u001b[39m Dense(num_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[0;32m---> 88\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43minputs_rp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_gaf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_mtf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/utils/tracking.py:26\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m DotNotTrackScope():\n\u001b[0;32m---> 26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/models/functional.py:135\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(is_input_keras_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m flat_inputs):\n\u001b[1;32m    133\u001b[0m     inputs, outputs \u001b[38;5;241m=\u001b[39m clone_graph_nodes(inputs, outputs)\n\u001b[0;32m--> 135\u001b[0m \u001b[43mFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m trainable\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/ops/function.py:77\u001b[0m, in \u001b[0;36mFunction.__init__\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m _self_setattr_tracking\n\u001b[0;32m---> 77\u001b[0m (nodes, nodes_by_depth, operations, operations_by_depth) \u001b[38;5;241m=\u001b[39m \u001b[43mmap_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_outputs\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes \u001b[38;5;241m=\u001b[39m nodes\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes_by_depth \u001b[38;5;241m=\u001b[39m nodes_by_depth\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/ops/function.py:331\u001b[0m, in \u001b[0;36mmap_graph\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m all_names:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m all_names\u001b[38;5;241m.\u001b[39mcount(name) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    332\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe name \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is used \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mall_names\u001b[38;5;241m.\u001b[39mcount(name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    333\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimes in the model. All operation names should be unique.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m         )\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m network_nodes, nodes_by_depth, operations, operations_by_depth\n",
      "\u001b[0;31mValueError\u001b[0m: The name \"block1_conv1\" is used 3 times in the model. All operation names should be unique."
     ]
    }
   ],
   "source": [
    "#pleasee this time workkkkkkkkk\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Concatenate, Dropout, Layer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Define a custom callback to print messages and store history\n",
    "class PrintLogger(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"\\nEpoch {epoch + 1} started.\")\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"\\nEpoch {epoch + 1} ended.\")\n",
    "        print(f\"Accuracy: {logs['accuracy']:.4f} - Loss: {logs['loss']:.4f} - Val Accuracy: {logs['val_accuracy']:.4f} - Val Loss: {logs['val_loss']:.4f}\")\n",
    "\n",
    "# Define directories\n",
    "save_dir = './split_datav3'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Load the split data\n",
    "X_rp_train = np.load(os.path.join(save_dir, 'X_rp_train.npy'))\n",
    "X_gaf_train = np.load(os.path.join(save_dir, 'X_gaf_train.npy'))\n",
    "X_mtf_train = np.load(os.path.join(save_dir, 'X_mtf_train.npy'))\n",
    "y_train = np.load(os.path.join(save_dir, 'y_train.npy'))\n",
    "\n",
    "X_rp_val = np.load(os.path.join(save_dir, 'X_rp_val.npy'))\n",
    "X_gaf_val = np.load(os.path.join(save_dir, 'X_gaf_val.npy'))\n",
    "X_mtf_val = np.load(os.path.join(save_dir, 'X_mtf_val.npy'))\n",
    "y_val = np.load(os.path.join(save_dir, 'y_val.npy'))\n",
    "\n",
    "X_rp_test = np.load(os.path.join(save_dir, 'X_rp_test.npy'))\n",
    "X_gaf_test = np.load(os.path.join(save_dir, 'X_gaf_test.npy'))\n",
    "X_mtf_test = np.load(os.path.join(save_dir, 'X_mtf_test.npy'))\n",
    "y_test = np.load(os.path.join(save_dir, 'y_test.npy'))\n",
    "\n",
    "# Remove the alpha channel to make the images 3-channel (RGB)\n",
    "def remove_alpha_channel(images):\n",
    "    return images[:, :, :, :3]\n",
    "\n",
    "X_rp_train = remove_alpha_channel(X_rp_train)\n",
    "X_gaf_train = remove_alpha_channel(X_gaf_train)\n",
    "X_mtf_train = remove_alpha_channel(X_mtf_train)\n",
    "\n",
    "X_rp_val = remove_alpha_channel(X_rp_val)\n",
    "X_gaf_val = remove_alpha_channel(X_gaf_val)\n",
    "X_mtf_val = remove_alpha_channel(X_mtf_val)\n",
    "\n",
    "X_rp_test = remove_alpha_channel(X_rp_test)\n",
    "X_gaf_test = remove_alpha_channel(X_gaf_test)\n",
    "X_mtf_test = remove_alpha_channel(X_mtf_test)\n",
    "\n",
    "# Define a function to build the VGG16 model with unique layer names\n",
    "def build_vgg16_model(input_shape, num_classes):\n",
    "    def get_vgg16_with_custom_names(input_tensor, suffix):\n",
    "        base_model = VGG16(include_top=False, input_tensor=input_tensor)\n",
    "        for layer in base_model.layers:\n",
    "            layer._name = f\"{layer.name}_{suffix}\"\n",
    "        return base_model\n",
    "    \n",
    "    inputs_rp = Input(shape=input_shape, name='rp_input')\n",
    "    inputs_gaf = Input(shape=input_shape, name='gaf_input')\n",
    "    inputs_mtf = Input(shape=input_shape, name='mtf_input')\n",
    "    \n",
    "    base_rp = get_vgg16_with_custom_names(inputs_rp, 'rp')\n",
    "    base_gaf = get_vgg16_with_custom_names(inputs_gaf, 'gaf')\n",
    "    base_mtf = get_vgg16_with_custom_names(inputs_mtf, 'mtf')\n",
    "    \n",
    "    x_rp = Flatten(name='flatten_rp')(base_rp.output)\n",
    "    x_gaf = Flatten(name='flatten_gaf')(base_gaf.output)\n",
    "    x_mtf = Flatten(name='flatten_mtf')(base_mtf.output)\n",
    "    \n",
    "    merged = Concatenate(name='merged')([x_rp, x_gaf, x_mtf])\n",
    "    \n",
    "    x = Dense(512, activation='relu', name='dense_512')(merged)\n",
    "    x = Dropout(0.5, name='dropout_512')(x)\n",
    "    x = Dense(128, activation='relu', name='dense_128')(x)\n",
    "    x = Dropout(0.5, name='dropout_128')(x)\n",
    "    outputs = Dense(num_classes, activation='softmax', name='output')(x)\n",
    "    \n",
    "    model = Model(inputs=[inputs_rp, inputs_gaf, inputs_mtf], outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (201, 201, 3)  # 3-channel input\n",
    "num_classes = 5\n",
    "\n",
    "# Build VGG16 model\n",
    "vgg16_model = build_vgg16_model(input_shape, num_classes)\n",
    "vgg16_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping and model checkpoint callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "vgg16_checkpoint = ModelCheckpoint(filepath=os.path.join(save_dir, 'vgg16_best_model.h5'), monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Train VGG16 model\n",
    "vgg16_history = vgg16_model.fit(\n",
    "    [X_rp_train, X_gaf_train, X_mtf_train], y_train,\n",
    "    epochs=10, batch_size=32, validation_data=([X_rp_val, X_gaf_val, X_mtf_val], y_val),\n",
    "    callbacks=[early_stopping, vgg16_checkpoint, PrintLogger()],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate VGG16 model on the test set\n",
    "vgg16_model.load_weights(os.path.join(save_dir, 'vgg16_best_model.h5'))\n",
    "vgg16_test_loss, vgg16_test_accuracy = vgg16_model.evaluate([X_rp_test, X_gaf_test, X_mtf_test], y_test)\n",
    "print(f'VGG16 Test loss: {vgg16_test_loss:.4f}')\n",
    "print(f'VGG16 Test accuracy: {vgg16_test_accuracy:.4f}')\n",
    "\n",
    "# Function to plot learning curves\n",
    "def plot_learning_curve(history, model_name):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot training & validation accuracy values\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(f'Model accuracy - {model_name}')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'Model loss - {model_name}')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot learning curve for VGG16\n",
    "plot_learning_curve(vgg16_history, 'VGG16')\n",
    "\n",
    "# Save the final VGG16 model\n",
    "vgg16_model.save(os.path.join(save_dir, 'vgg16_model.h5'))\n",
    "\n",
    "# Save the training history\n",
    "with open(os.path.join(save_dir, 'vgg16_history.json'), 'w') as f:\n",
    "    json.dump(vgg16_history.history, f)\n",
    "\n",
    "print(f\"VGG16 model and history saved in directory: {save_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The name \"block1_conv1\" is used 3 times in the model. All operation names should be unique.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 97\u001b[0m\n\u001b[1;32m     94\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Build VGG16 model\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m vgg16_model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_vgg16_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m vgg16_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Define early stopping and model checkpoint callbacks\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 89\u001b[0m, in \u001b[0;36mbuild_vgg16_model\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m     86\u001b[0m x \u001b[38;5;241m=\u001b[39m Dropout(\u001b[38;5;241m0.5\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout_128\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[1;32m     87\u001b[0m outputs \u001b[38;5;241m=\u001b[39m Dense(num_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[0;32m---> 89\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43minputs_rp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_gaf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_mtf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/utils/tracking.py:26\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m DotNotTrackScope():\n\u001b[0;32m---> 26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/models/functional.py:135\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(is_input_keras_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m flat_inputs):\n\u001b[1;32m    133\u001b[0m     inputs, outputs \u001b[38;5;241m=\u001b[39m clone_graph_nodes(inputs, outputs)\n\u001b[0;32m--> 135\u001b[0m \u001b[43mFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m trainable\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/ops/function.py:77\u001b[0m, in \u001b[0;36mFunction.__init__\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m _self_setattr_tracking\n\u001b[0;32m---> 77\u001b[0m (nodes, nodes_by_depth, operations, operations_by_depth) \u001b[38;5;241m=\u001b[39m \u001b[43mmap_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_outputs\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes \u001b[38;5;241m=\u001b[39m nodes\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes_by_depth \u001b[38;5;241m=\u001b[39m nodes_by_depth\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/ops/function.py:331\u001b[0m, in \u001b[0;36mmap_graph\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m all_names:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m all_names\u001b[38;5;241m.\u001b[39mcount(name) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    332\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe name \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is used \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mall_names\u001b[38;5;241m.\u001b[39mcount(name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    333\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimes in the model. All operation names should be unique.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m         )\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m network_nodes, nodes_by_depth, operations, operations_by_depth\n",
      "\u001b[0;31mValueError\u001b[0m: The name \"block1_conv1\" is used 3 times in the model. All operation names should be unique."
     ]
    }
   ],
   "source": [
    "#noooo please this timeeeeee\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Concatenate, Dropout, Layer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Define a custom callback to print messages and store history\n",
    "class PrintLogger(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"\\nEpoch {epoch + 1} started.\")\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"\\nEpoch {epoch + 1} ended.\")\n",
    "        print(f\"Accuracy: {logs['accuracy']:.4f} - Loss: {logs['loss']:.4f} - Val Accuracy: {logs['val_accuracy']:.4f} - Val Loss: {logs['val_loss']:.4f}\")\n",
    "\n",
    "# Define directories\n",
    "save_dir = './split_datav3'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Load the split data\n",
    "X_rp_train = np.load(os.path.join(save_dir, 'X_rp_train.npy'))\n",
    "X_gaf_train = np.load(os.path.join(save_dir, 'X_gaf_train.npy'))\n",
    "X_mtf_train = np.load(os.path.join(save_dir, 'X_mtf_train.npy'))\n",
    "y_train = np.load(os.path.join(save_dir, 'y_train.npy'))\n",
    "\n",
    "X_rp_val = np.load(os.path.join(save_dir, 'X_rp_val.npy'))\n",
    "X_gaf_val = np.load(os.path.join(save_dir, 'X_gaf_val.npy'))\n",
    "X_mtf_val = np.load(os.path.join(save_dir, 'X_mtf_val.npy'))\n",
    "y_val = np.load(os.path.join(save_dir, 'y_val.npy'))\n",
    "\n",
    "X_rp_test = np.load(os.path.join(save_dir, 'X_rp_test.npy'))\n",
    "X_gaf_test = np.load(os.path.join(save_dir, 'X_gaf_test.npy'))\n",
    "X_mtf_test = np.load(os.path.join(save_dir, 'X_mtf_test.npy'))\n",
    "y_test = np.load(os.path.join(save_dir, 'y_test.npy'))\n",
    "\n",
    "# Remove the alpha channel to make the images 3-channel (RGB)\n",
    "def remove_alpha_channel(images):\n",
    "    return images[:, :, :, :3]\n",
    "\n",
    "X_rp_train = remove_alpha_channel(X_rp_train)\n",
    "X_gaf_train = remove_alpha_channel(X_gaf_train)\n",
    "X_mtf_train = remove_alpha_channel(X_mtf_train)\n",
    "\n",
    "X_rp_val = remove_alpha_channel(X_rp_val)\n",
    "X_gaf_val = remove_alpha_channel(X_gaf_val)\n",
    "X_mtf_val = remove_alpha_channel(X_mtf_val)\n",
    "\n",
    "X_rp_test = remove_alpha_channel(X_rp_test)\n",
    "X_gaf_test = remove_alpha_channel(X_gaf_test)\n",
    "X_mtf_test = remove_alpha_channel(X_mtf_test)\n",
    "\n",
    "# Define a function to build the VGG16 model with unique layer names\n",
    "def build_vgg16_model(input_shape, num_classes):\n",
    "    def get_vgg16_with_custom_names(input_tensor, suffix):\n",
    "        with tf.keras.utils.custom_object_scope({'VGG16': VGG16}):\n",
    "            base_model = VGG16(include_top=False, input_tensor=input_tensor)\n",
    "            for layer in base_model.layers:\n",
    "                layer._name = f\"{layer.name}_{suffix}\"\n",
    "        return base_model\n",
    "    \n",
    "    inputs_rp = Input(shape=input_shape, name='rp_input')\n",
    "    inputs_gaf = Input(shape=input_shape, name='gaf_input')\n",
    "    inputs_mtf = Input(shape=input_shape, name='mtf_input')\n",
    "    \n",
    "    base_rp = get_vgg16_with_custom_names(inputs_rp, 'rp')\n",
    "    base_gaf = get_vgg16_with_custom_names(inputs_gaf, 'gaf')\n",
    "    base_mtf = get_vgg16_with_custom_names(inputs_mtf, 'mtf')\n",
    "    \n",
    "    x_rp = Flatten(name='flatten_rp')(base_rp.output)\n",
    "    x_gaf = Flatten(name='flatten_gaf')(base_gaf.output)\n",
    "    x_mtf = Flatten(name='flatten_mtf')(base_mtf.output)\n",
    "    \n",
    "    merged = Concatenate(name='merged')([x_rp, x_gaf, x_mtf])\n",
    "    \n",
    "    x = Dense(512, activation='relu', name='dense_512')(merged)\n",
    "    x = Dropout(0.5, name='dropout_512')(x)\n",
    "    x = Dense(128, activation='relu', name='dense_128')(x)\n",
    "    x = Dropout(0.5, name='dropout_128')(x)\n",
    "    outputs = Dense(num_classes, activation='softmax', name='output')(x)\n",
    "    \n",
    "    model = Model(inputs=[inputs_rp, inputs_gaf, inputs_mtf], outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (201, 201, 3)  # 3-channel input\n",
    "num_classes = 5\n",
    "\n",
    "# Build VGG16 model\n",
    "vgg16_model = build_vgg16_model(input_shape, num_classes)\n",
    "vgg16_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping and model checkpoint callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "vgg16_checkpoint = ModelCheckpoint(filepath=os.path.join(save_dir, 'vgg16_best_model.h5'), monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Train VGG16 model\n",
    "vgg16_history = vgg16_model.fit(\n",
    "    [X_rp_train, X_gaf_train, X_mtf_train], y_train,\n",
    "    epochs=10, batch_size=32, validation_data=([X_rp_val, X_gaf_val, X_mtf_val], y_val),\n",
    "    callbacks=[early_stopping, vgg16_checkpoint, PrintLogger()],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate VGG16 model on the test set\n",
    "vgg16_model.load_weights(os.path.join(save_dir, 'vgg16_best_model.h5'))\n",
    "vgg16_test_loss, vgg16_test_accuracy = vgg16_model.evaluate([X_rp_test, X_gaf_test, X_mtf_test], y_test)\n",
    "print(f'VGG16 Test loss: {vgg16_test_loss:.4f}')\n",
    "print(f'VGG16 Test accuracy: {vgg16_test_accuracy:.4f}')\n",
    "\n",
    "# Function to plot learning curves\n",
    "def plot_learning_curve(history, model_name):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot training & validation accuracy values\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(f'Model accuracy - {model_name}')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'Model loss - {model_name}')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot learning curve for VGG16\n",
    "plot_learning_curve(vgg16_history, 'VGG16')\n",
    "\n",
    "# Save the final VGG16 model\n",
    "vgg16_model.save(os.path.join(save_dir, 'vgg16_model.h5'))\n",
    "\n",
    "# Save the training history\n",
    "with open(os.path.join(save_dir, 'vgg16_history.json'), 'w') as f:\n",
    "    json.dump(vgg16_history.history, f)\n",
    "\n",
    "print(f\"VGG16 model and history saved in directory: {save_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The shape of the target variable and the shape of the target value in `variable.assign(value)` must match. variable.shape=(3, 3, 4, 64), Received: value.shape=(3, 3, 3, 64). Target variable: <KerasVariable shape=(3, 3, 4, 64), dtype=float32, path=block1_conv1/kernel>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Build VGG16 model\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m vgg16_model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_vgg16_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m vgg16_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Define early stopping and model checkpoint callbacks\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 51\u001b[0m, in \u001b[0;36mbuild_vgg16_model\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m     48\u001b[0m inputs_gaf \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39minput_shape, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_gaf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     49\u001b[0m inputs_mtf \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39minput_shape, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_mtf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m base_rp \u001b[38;5;241m=\u001b[39m \u001b[43mVGG16\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_rp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvgg16_rp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m base_gaf \u001b[38;5;241m=\u001b[39m VGG16(include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, input_tensor\u001b[38;5;241m=\u001b[39minputs_gaf, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvgg16_gaf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     53\u001b[0m base_mtf \u001b[38;5;241m=\u001b[39m VGG16(include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, input_tensor\u001b[38;5;241m=\u001b[39minputs_mtf, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvgg16_mtf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/applications/vgg16.py:224\u001b[0m, in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m         weights_path \u001b[38;5;241m=\u001b[39m file_utils\u001b[38;5;241m.\u001b[39mget_file(\n\u001b[1;32m    219\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m             WEIGHTS_PATH_NO_TOP,\n\u001b[1;32m    221\u001b[0m             cache_subdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m             file_hash\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m6d6bbae143d832006294945121d1f1fc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         )\n\u001b[0;32m--> 224\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_weights(weights)\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/backend/common/variables.py:226\u001b[0m, in \u001b[0;36mKerasVariable.assign\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    224\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_to_tensor(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m shape_equal(value\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m--> 226\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe shape of the target variable and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe shape of the target value in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`variable.assign(value)` must match. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariable.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: value.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget variable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m     )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m in_stateless_scope():\n\u001b[1;32m    235\u001b[0m     scope \u001b[38;5;241m=\u001b[39m get_stateless_scope()\n",
      "\u001b[0;31mValueError\u001b[0m: The shape of the target variable and the shape of the target value in `variable.assign(value)` must match. variable.shape=(3, 3, 4, 64), Received: value.shape=(3, 3, 3, 64). Target variable: <KerasVariable shape=(3, 3, 4, 64), dtype=float32, path=block1_conv1/kernel>"
     ]
    }
   ],
   "source": [
    "#noooo\n",
    "# VGG16\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Concatenate, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Define a custom callback to print messages and store history\n",
    "class PrintLogger(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"\\nEpoch {epoch + 1} started.\")\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"\\nEpoch {epoch + 1} ended.\")\n",
    "        print(f\"Accuracy: {logs['accuracy']:.4f} - Loss: {logs['loss']:.4f} - Val Accuracy: {logs['val_accuracy']:.4f} - Val Loss: {logs['val_loss']:.4f}\")\n",
    "\n",
    "# Define directories\n",
    "save_dir = './split_datav3'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Load the split data\n",
    "X_rp_train = np.load(os.path.join(save_dir, 'X_rp_train.npy'))\n",
    "X_gaf_train = np.load(os.path.join(save_dir, 'X_gaf_train.npy'))\n",
    "X_mtf_train = np.load(os.path.join(save_dir, 'X_mtf_train.npy'))\n",
    "y_train = np.load(os.path.join(save_dir, 'y_train.npy'))\n",
    "\n",
    "X_rp_val = np.load(os.path.join(save_dir, 'X_rp_val.npy'))\n",
    "X_gaf_val = np.load(os.path.join(save_dir, 'X_gaf_val.npy'))\n",
    "X_mtf_val = np.load(os.path.join(save_dir, 'X_mtf_val.npy'))\n",
    "y_val = np.load(os.path.join(save_dir, 'y_val.npy'))\n",
    "\n",
    "X_rp_test = np.load(os.path.join(save_dir, 'X_rp_test.npy'))\n",
    "X_gaf_test = np.load(os.path.join(save_dir, 'X_gaf_test.npy'))\n",
    "X_mtf_test = np.load(os.path.join(save_dir, 'X_mtf_test.npy'))\n",
    "y_test = np.load(os.path.join(save_dir, 'y_test.npy'))\n",
    "\n",
    "# Define a function to build the VGG16 model\n",
    "def build_vgg16_model(input_shape, num_classes):\n",
    "    inputs_rp = Input(shape=input_shape, name='input_rp')\n",
    "    inputs_gaf = Input(shape=input_shape, name='input_gaf')\n",
    "    inputs_mtf = Input(shape=input_shape, name='input_mtf')\n",
    "    \n",
    "    base_rp = VGG16(include_top=False, input_tensor=inputs_rp, weights='imagenet', name='vgg16_rp')\n",
    "    base_gaf = VGG16(include_top=False, input_tensor=inputs_gaf, weights='imagenet', name='vgg16_gaf')\n",
    "    base_mtf = VGG16(include_top=False, input_tensor=inputs_mtf, weights='imagenet', name='vgg16_mtf')\n",
    "    \n",
    "    x_rp = Flatten(name='flatten_rp')(base_rp.output)\n",
    "    x_gaf = Flatten(name='flatten_gaf')(base_gaf.output)\n",
    "    x_mtf = Flatten(name='flatten_mtf')(base_mtf.output)\n",
    "    \n",
    "    merged = Concatenate(name='concat')([x_rp, x_gaf, x_mtf])\n",
    "    \n",
    "    x = Dense(512, activation='relu', name='dense_512')(merged)\n",
    "    x = Dropout(0.5, name='dropout_512')(x)\n",
    "    x = Dense(128, activation='relu', name='dense_128')(x)\n",
    "    x = Dropout(0.5, name='dropout_128')(x)\n",
    "    outputs = Dense(num_classes, activation='softmax', name='output')(x)\n",
    "    \n",
    "    model = Model(inputs=[inputs_rp, inputs_gaf, inputs_mtf], outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (201, 201, 4)\n",
    "num_classes = 5\n",
    "\n",
    "# Build VGG16 model\n",
    "vgg16_model = build_vgg16_model(input_shape, num_classes)\n",
    "vgg16_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping and model checkpoint callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "vgg16_checkpoint = ModelCheckpoint(filepath=os.path.join(save_dir, 'vgg16_best_model.h5'), monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Train VGG16 model\n",
    "vgg16_history = vgg16_model.fit(\n",
    "    [X_rp_train, X_gaf_train, X_mtf_train], y_train,\n",
    "    epochs=10, batch_size=32, validation_data=([X_rp_val, X_gaf_val, X_mtf_val], y_val),\n",
    "    callbacks=[early_stopping, vgg16_checkpoint, PrintLogger()],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate VGG16 model on the test set\n",
    "vgg16_model.load_weights(os.path.join(save_dir, 'vgg16_best_model.h5'))\n",
    "vgg16_test_loss, vgg16_test_accuracy = vgg16_model.evaluate([X_rp_test, X_gaf_test, X_mtf_test], y_test)\n",
    "print(f'VGG16 Test loss: {vgg16_test_loss:.4f}')\n",
    "print(f'VGG16 Test accuracy: {vgg16_test_accuracy:.4f}')\n",
    "\n",
    "# Function to plot learning curves\n",
    "def plot_learning_curve(history, model_name):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot training & validation accuracy values\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(f'Model accuracy - {model_name}')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'Model loss - {model_name}')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot learning curve for VGG16\n",
    "plot_learning_curve(vgg16_history, 'VGG16')\n",
    "\n",
    "# Save the final VGG16 model\n",
    "vgg16_model.save(os.path.join(save_dir, 'vgg16_model.h5'))\n",
    "\n",
    "# Save the training history\n",
    "with open(os.path.join(save_dir, 'vgg16_history.json'), 'w') as f:\n",
    "    json.dump(vgg16_history.history, f)\n",
    "\n",
    "print(f\"VGG16 model and history saved in directory: {save_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The name \"block1_conv1\" is used 3 times in the model. All operation names should be unique.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 96\u001b[0m\n\u001b[1;32m     93\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Build VGG16 model\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m vgg16_model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_vgg16_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m vgg16_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Define early stopping and model checkpoint callbacks\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 88\u001b[0m, in \u001b[0;36mbuild_vgg16_model\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m     85\u001b[0m x \u001b[38;5;241m=\u001b[39m Dropout(\u001b[38;5;241m0.5\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout_128\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[1;32m     86\u001b[0m outputs \u001b[38;5;241m=\u001b[39m Dense(num_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[0;32m---> 88\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43minputs_rp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_gaf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_mtf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/utils/tracking.py:26\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m DotNotTrackScope():\n\u001b[0;32m---> 26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/models/functional.py:135\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(is_input_keras_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m flat_inputs):\n\u001b[1;32m    133\u001b[0m     inputs, outputs \u001b[38;5;241m=\u001b[39m clone_graph_nodes(inputs, outputs)\n\u001b[0;32m--> 135\u001b[0m \u001b[43mFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m trainable\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/ops/function.py:77\u001b[0m, in \u001b[0;36mFunction.__init__\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m _self_setattr_tracking\n\u001b[0;32m---> 77\u001b[0m (nodes, nodes_by_depth, operations, operations_by_depth) \u001b[38;5;241m=\u001b[39m \u001b[43mmap_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_outputs\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes \u001b[38;5;241m=\u001b[39m nodes\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes_by_depth \u001b[38;5;241m=\u001b[39m nodes_by_depth\n",
      "File \u001b[0;32m~/miniconda3/envs/newtestv2/lib/python3.12/site-packages/keras/src/ops/function.py:331\u001b[0m, in \u001b[0;36mmap_graph\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m all_names:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m all_names\u001b[38;5;241m.\u001b[39mcount(name) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    332\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe name \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is used \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mall_names\u001b[38;5;241m.\u001b[39mcount(name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    333\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimes in the model. All operation names should be unique.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m         )\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m network_nodes, nodes_by_depth, operations, operations_by_depth\n",
      "\u001b[0;31mValueError\u001b[0m: The name \"block1_conv1\" is used 3 times in the model. All operation names should be unique."
     ]
    }
   ],
   "source": [
    "#Alternative: Using clone_model to create separate copies of the VGG16 model for each input. This ensures unique layer names automatically. \n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model, clone_model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Concatenate, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Define a custom callback to print messages and store history\n",
    "class PrintLogger(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"\\nEpoch {epoch + 1} started.\")\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"\\nEpoch {epoch + 1} ended.\")\n",
    "        print(f\"Accuracy: {logs['accuracy']:.4f} - Loss: {logs['loss']:.4f} - Val Accuracy: {logs['val_accuracy']:.4f} - Val Loss: {logs['val_loss']:.4f}\")\n",
    "\n",
    "# Define directories\n",
    "save_dir = './split_datav3'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Load the split data\n",
    "X_rp_train = np.load(os.path.join(save_dir, 'X_rp_train.npy'))\n",
    "X_gaf_train = np.load(os.path.join(save_dir, 'X_gaf_train.npy'))\n",
    "X_mtf_train = np.load(os.path.join(save_dir, 'X_mtf_train.npy'))\n",
    "y_train = np.load(os.path.join(save_dir, 'y_train.npy'))\n",
    "\n",
    "X_rp_val = np.load(os.path.join(save_dir, 'X_rp_val.npy'))\n",
    "X_gaf_val = np.load(os.path.join(save_dir, 'X_gaf_val.npy'))\n",
    "X_mtf_val = np.load(os.path.join(save_dir, 'X_mtf_val.npy'))\n",
    "y_val = np.load(os.path.join(save_dir, 'y_val.npy'))\n",
    "\n",
    "X_rp_test = np.load(os.path.join(save_dir, 'X_rp_test.npy'))\n",
    "X_gaf_test = np.load(os.path.join(save_dir, 'X_gaf_test.npy'))\n",
    "X_mtf_test = np.load(os.path.join(save_dir, 'X_mtf_test.npy'))\n",
    "y_test = np.load(os.path.join(save_dir, 'y_test.npy'))\n",
    "\n",
    "# Resize images to (224, 224, 3) and keep only RGB channels\n",
    "def resize_images(images):\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        img = tf.image.resize(img, [224, 224])\n",
    "        img = img[:, :, :3]  # Keep only RGB channels\n",
    "        resized_images.append(img)\n",
    "    return np.array(resized_images)\n",
    "\n",
    "X_rp_train = resize_images(X_rp_train)\n",
    "X_gaf_train = resize_images(X_gaf_train)\n",
    "X_mtf_train = resize_images(X_mtf_train)\n",
    "X_rp_val = resize_images(X_rp_val)\n",
    "X_gaf_val = resize_images(X_gaf_val)\n",
    "X_mtf_val = resize_images(X_mtf_val)\n",
    "X_rp_test = resize_images(X_rp_test)\n",
    "X_gaf_test = resize_images(X_gaf_test)\n",
    "X_mtf_test = resize_images(X_mtf_test)\n",
    "\n",
    "# Define a function to build the VGG16 model\n",
    "def build_vgg16_model(input_shape, num_classes):\n",
    "    inputs_rp = Input(shape=input_shape, name='input_rp')\n",
    "    inputs_gaf = Input(shape=input_shape, name='input_gaf')\n",
    "    inputs_mtf = Input(shape=input_shape, name='input_mtf')\n",
    "\n",
    "    base_model = VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    # Clone the base model for each input with unique names\n",
    "    base_rp = clone_model(base_model, input_tensors=inputs_rp)\n",
    "    base_gaf = clone_model(base_model, input_tensors=inputs_gaf)\n",
    "    base_mtf = clone_model(base_model, input_tensors=inputs_mtf)\n",
    "\n",
    "    x_rp = Flatten(name='flatten_rp')(base_rp.output)\n",
    "    x_gaf = Flatten(name='flatten_gaf')(base_gaf.output)\n",
    "    x_mtf = Flatten(name='flatten_mtf')(base_mtf.output)\n",
    "\n",
    "    merged = Concatenate(name='concat')([x_rp, x_gaf, x_mtf])\n",
    "\n",
    "    x = Dense(512, activation='relu', name='dense_512')(merged)\n",
    "    x = Dropout(0.5, name='dropout_512')(x)\n",
    "    x = Dense(128, activation='relu', name='dense_128')(x)\n",
    "    x = Dropout(0.5, name='dropout_128')(x)\n",
    "    outputs = Dense(num_classes, activation='softmax', name='output')(x)\n",
    "\n",
    "    model = Model(inputs=[inputs_rp, inputs_gaf, inputs_mtf], outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = 5\n",
    "\n",
    "# Build VGG16 model\n",
    "vgg16_model = build_vgg16_model(input_shape, num_classes)\n",
    "vgg16_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping and model checkpoint callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "vgg16_checkpoint = ModelCheckpoint(filepath=os.path.join(save_dir, 'vgg16_best_model.h5'), monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Train VGG16 model\n",
    "vgg16_history = vgg16_model.fit(\n",
    "    [X_rp_train, X_gaf_train, X_mtf_train], y_train,\n",
    "    epochs=10, batch_size=32, validation_data=([X_rp_val, X_gaf_val, X_mtf_val], y_val),\n",
    "    callbacks=[early_stopping, vgg16_checkpoint, PrintLogger()],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate VGG16 model on the test set\n",
    "vgg16_model.load_weights(os.path.join(save_dir, 'vgg16_best_model.h5'))\n",
    "vgg16_test_loss, vgg16_test_accuracy = vgg16_model.evaluate([X_rp_test, X_gaf_test, X_mtf_test], y_test)\n",
    "print(f'VGG16 Test loss: {vgg16_test_loss:.4f}')\n",
    "print(f'VGG16 Test accuracy: {vgg16_test_accuracy:.4f}')\n",
    "\n",
    "# Function to plot learning curves\n",
    "def plot_learning_curve(history, model_name):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(f'Model accuracy - {model_name}')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'Model loss - {model_name}')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot learning curve for VGG16\n",
    "plot_learning_curve(vgg16_history, 'VGG16')\n",
    "\n",
    "# Save the final VGG16 model\n",
    "vgg16_model.save(os.path.join(save_dir, 'vgg16_model.h5'))\n",
    "\n",
    "# Save the training history\n",
    "with open(os.path.join(save_dir, 'vgg16_history.json'), 'w') as f:\n",
    "    json.dump(vgg16_history.history, f)\n",
    "\n",
    "print(f\"VGG16 model and history saved in directory: {save_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newtestv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
